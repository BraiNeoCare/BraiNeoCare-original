{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np \n",
    "from scipy import signal \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../BraiNeoCare/Datasets/GAT/traindata_18.npy',mmap_mode='r')\n",
    "y_train = np.load('../BraiNeoCare/Datasets/GAT/trainlabels_18.npy',mmap_mode='r')\n",
    "x_test = np.load('../BraiNeoCare/Datasets/GAT/testdata_18.npy',mmap_mode='r')\n",
    "y_test = np.load('../BraiNeoCare/Datasets/GAT/testlabels_18.npy',mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=x_train.mean()\n",
    "std=x_train.std()\n",
    "x_train=(x_train-mean)/std\n",
    "x_test=(x_test-mean)/std\n",
    "# x1=(x1-mean)/std\n",
    "\n",
    "x_train=np.expand_dims(x_train,axis=-1)\n",
    "x_test=np.expand_dims(x_test,axis=-1)\n",
    "# x1=np.expand_dims(x1,axis=-1)\n",
    "\n",
    "np.random.seed(25)\n",
    "train_indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(train_indices)\n",
    "x_train = x_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "# test_indices = np.arange(x_test.shape[0])   \n",
    "# np.random.shuffle(test_indices)\n",
    "# x_test = x_test[test_indices]\n",
    "# y_test = y_test[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names=[\"Fp1-T3\",\"T3-O1\",\"Fp1-C3\",\"C3-O1\",\"Fp2-C4\",\"C4-O2\",\"Fp2-T4\",\"T4-O2\",\"T3-C3\",\"C3-Cz\",\"Cz-C4\",\"C4-T4\"]\n",
    "indices =[[r,i] for r,c1 in enumerate(channel_names) for i,c2 in enumerate(channel_names) if (c1.split(\"-\")[0]==c2.split(\"-\")[1] or c1.split(\"-\")[1]==c2.split(\"-\")[1] \n",
    "          or c1.split(\"-\")[0]==c2.split(\"-\")[0] or c1.split(\"-\")[1]==c2.split(\"-\")[0])]\n",
    "adj=np.zeros((12,12))\n",
    "for i in indices:\n",
    "    adj[i[0]][i[1]]=1\n",
    "adj=tf.constant(adj,dtype=tf.float32)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self,output_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.LeakyReLU = layers.LeakyReLU(alpha=0.2)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',shape=(input_shape[-1], self.output_dim), initializer='random_normal',trainable=True)\n",
    "        self.a = self.add_weight(name='a',shape=(2*self.output_dim, 1), initializer='random_normal',trainable=True)\n",
    "    \n",
    "    def call(self,input,adj):\n",
    "        H= tf.matmul(input, self.W)\n",
    "        h1=tf.tile(tf.expand_dims(H, axis=1), [1,12,1,1])\n",
    "        h2=tf.tile(tf.expand_dims(H, axis=2), [1,1,12,1])\n",
    "        result =tf.concat([h1 , h2], axis=-1)\n",
    "        e=self.LeakyReLU(tf.squeeze(tf.matmul(result, self.a),axis=-1))\n",
    "        zero_mat=-1e20*tf.zeros_like(e)\n",
    "        msked_e=tf.where(adj==1,e,zero_mat)\n",
    "        alpha=tf.nn.softmax(msked_e,axis=-1)\n",
    "        HPrime=tf.matmul(alpha,H)\n",
    "        return tf.nn.elu(HPrime)\n",
    "\n",
    "\n",
    "Input= keras.Input(shape=(18,384,1))\n",
    "\n",
    "x= layers.Conv2D(32,(1,5),activation='relu',padding='same')(Input)\n",
    "y= layers.Conv2D(32,(1,7),activation='relu',padding='same')(Input)\n",
    "x= layers.add([x,y])\n",
    "x= layers.AveragePooling2D((1,2))(x)\n",
    "x= layers.BatchNormalization()(x)\n",
    "x= layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "x= layers.Conv2D(64,(1,5),activation='relu',padding='same')(x)\n",
    "y= layers.SpatialDropout2D(0.2)(x)\n",
    "y= layers.Conv2D(64,(1,7),activation='relu',padding='same')(y)\n",
    "x= layers.add([x,y])\n",
    "x= layers.AveragePooling2D((1,2))(x)\n",
    "x= layers.BatchNormalization()(x)\n",
    "x= layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "x= layers.Conv2D(8,(1,5),activation='relu',padding='same')(x)\n",
    "y= layers.SpatialDropout2D(0.2)(x)\n",
    "y= layers.Conv2D(8,(1,7),activation='relu',padding='same')(y)\n",
    "x= layers.add([x,y])\n",
    "x= layers.AveragePooling2D((1,2))(x)\n",
    "x= layers.BatchNormalization()(x)\n",
    "x= layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "x= layers.Conv2D(1,(1,5),activation='relu',padding='same')(x)\n",
    "y= layers.SpatialDropout2D(0.2)(x)\n",
    "y= layers.Conv2D(1,(1,7),activation='relu',padding='same')(y)\n",
    "x= layers.add([x,y])\n",
    "x= layers.AveragePooling2D((1,2))(x)\n",
    "x= layers.Reshape((12,24))(x)\n",
    "\n",
    "x= GATLayer(37)(x,adj)\n",
    "x= GATLayer(32)(x,adj)\n",
    "x= GATLayer(16)(x,adj)\n",
    "\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x= layers.Dense(32,activation='relu')(x)\n",
    "x= layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(16,activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=Input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.002,weight_decay=0.0025)\n",
    "loss=keras.losses.BinaryFocalCrossentropy(from_logits=False,gamma=2,alpha=0.4,apply_class_balancing=True)\n",
    "# loss=keras.losses.BinaryCrossentropy(from_logits=False)  \n",
    "kappa=tfa.metrics.CohenKappa(num_classes=2)\n",
    "fp=keras.metrics.FalsePositives()\n",
    "tn=keras.metrics.TrueNegatives()\n",
    "precision = keras.metrics.Precision()\n",
    "recall = keras.metrics.Recall()\n",
    "AUROC = keras.metrics.AUC(curve='ROC', name = 'AUROC')\n",
    "AUPRC = keras.metrics.AUC(curve='PR', name = 'AUPRC')\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=['accuracy', AUROC, AUPRC,fp,tn, precision, recall,kappa])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"GAT_correct_rem_art-1/cp_{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path) \n",
    "cp_callback=keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=False,verbose=0,save_best_only=True,monitor='val_accuracy')  \n",
    "history=model.fit(x_train,y_train,epochs=200,batch_size=512,verbose=1,validation_data=(x_test,y_test),callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history_GAT_correct_5i.jason\", 'w') as f:\n",
    "    pd.DataFrame(history.history).to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss and accuracy for each epoch for 4s partitions\n",
    "with open('history_GAT_correct_5.jason','r') as f:\n",
    "    history_1 = pd.read_json(f)\n",
    "\n",
    "# with open('history_GAT_rem_art.jason','r') as f:\n",
    "#     history_2 = pd.read_json(f)\n",
    "\n",
    "metrics=['accuracy','val_accuracy','loss','val_loss','val_AUROC','val_AUPRC','val_precision','val_recall','recall','precision','AUROC','AUPRC']\n",
    "\n",
    "epochs = range(1, 201)\n",
    "\n",
    "fig,ax=plt.subplots(4,3,figsize=(20,20))\n",
    "\n",
    "for r in range(12):\n",
    "    ax[r//3][r%3].plot(epochs,history_1[metrics[r]],label=metrics[r],color='r')\n",
    "    # ax[r//3][r%3].plot(epochs,history_2[metrics[r]],label=metrics[r],color='g')\n",
    "    ax[r//3][r%3].set_title(metrics[r])\n",
    "    ax[r//3][r%3].set_xlabel('Epochs')\n",
    "    # ax[r//3][r%3].axhline(y=0.975, color='r', linestyle='-')\n",
    "    # ax[r//3][r%3].axvline(x=197, color='b', linestyle='-')\n",
    "    ax[r//3][r%3].grid()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1['val_accuracy'].max() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainNeoCare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
